[2024-07-01T11:06:46.126-0400] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-01T11:06:46.151-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T11:06:46.157-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T11:06:46.158-0400] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-07-01T11:06:46.198-0400] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_with_spark> on 2024-07-01 04:00:00+00:00
[2024-07-01T11:06:46.210-0400] {standard_task_runner.py:63} INFO - Started process 381944 to run task
[2024-07-01T11:06:46.217-0400] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'api_cuevana3_movie', 'transform_with_spark', 'scheduled__2024-07-01T04:00:00+00:00', '--job-id', '662', '--raw', '--subdir', 'DAGS_FOLDER/movie_recommend.py', '--cfg-path', '/tmp/tmp6o9hw0pf']
[2024-07-01T11:06:46.222-0400] {standard_task_runner.py:91} INFO - Job 662: Subtask transform_with_spark
[2024-07-01T11:06:46.280-0400] {task_command.py:426} INFO - Running <TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [running]> on host walter-VirtualBox
[2024-07-01T11:06:46.503-0400] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='api_cuevana3_movie' AIRFLOW_CTX_TASK_ID='transform_with_spark' AIRFLOW_CTX_EXECUTION_DATE='2024-07-01T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-01T04:00:00+00:00'
[2024-07-01T11:06:46.508-0400] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-01T11:06:46.533-0400] {logging_mixin.py:188} INFO - No se pudo obtener el JSON de datos de la pelicula
[2024-07-01T11:06:46.534-0400] {python.py:237} INFO - Done. Returned value was: None
[2024-07-01T11:06:46.534-0400] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-01T11:06:46.540-0400] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=api_cuevana3_movie, task_id=transform_with_spark, run_id=scheduled__2024-07-01T04:00:00+00:00, execution_date=20240701T040000, start_date=20240701T150646, end_date=20240701T150646
[2024-07-01T11:06:46.605-0400] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-01T11:06:46.634-0400] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-01T11:06:46.635-0400] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-01T11:17:49.390-0400] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-01T11:17:49.416-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T11:17:49.427-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T11:17:49.427-0400] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-07-01T11:17:49.450-0400] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_with_spark> on 2024-07-01 04:00:00+00:00
[2024-07-01T11:17:49.459-0400] {standard_task_runner.py:63} INFO - Started process 383176 to run task
[2024-07-01T11:17:49.465-0400] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'api_cuevana3_movie', 'transform_with_spark', 'scheduled__2024-07-01T04:00:00+00:00', '--job-id', '680', '--raw', '--subdir', 'DAGS_FOLDER/movie_recommend.py', '--cfg-path', '/tmp/tmp9_ht2_fn']
[2024-07-01T11:17:49.468-0400] {standard_task_runner.py:91} INFO - Job 680: Subtask transform_with_spark
[2024-07-01T11:17:49.527-0400] {task_command.py:426} INFO - Running <TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [running]> on host walter-VirtualBox
[2024-07-01T11:17:49.628-0400] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='api_cuevana3_movie' AIRFLOW_CTX_TASK_ID='transform_with_spark' AIRFLOW_CTX_EXECUTION_DATE='2024-07-01T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-01T04:00:00+00:00'
[2024-07-01T11:17:49.629-0400] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-01T11:17:49.645-0400] {logging_mixin.py:188} INFO - No se pudo obtener el JSON de datos de la pelicula
[2024-07-01T11:17:49.645-0400] {python.py:237} INFO - Done. Returned value was: None
[2024-07-01T11:17:49.646-0400] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-01T11:17:49.648-0400] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=api_cuevana3_movie, task_id=transform_with_spark, run_id=scheduled__2024-07-01T04:00:00+00:00, execution_date=20240701T040000, start_date=20240701T151749, end_date=20240701T151749
[2024-07-01T11:17:49.701-0400] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-01T11:17:49.718-0400] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-01T11:17:49.720-0400] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-01T19:23:02.920-0400] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-01T19:23:02.939-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T19:23:02.950-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T19:23:02.951-0400] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-07-01T19:23:02.969-0400] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_with_spark> on 2024-07-01 04:00:00+00:00
[2024-07-01T19:23:02.975-0400] {standard_task_runner.py:63} INFO - Started process 409098 to run task
[2024-07-01T19:23:02.978-0400] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'api_cuevana3_movie', 'transform_with_spark', 'scheduled__2024-07-01T04:00:00+00:00', '--job-id', '702', '--raw', '--subdir', 'DAGS_FOLDER/movie_recommend.py', '--cfg-path', '/tmp/tmpdyjxj2rb']
[2024-07-01T19:23:02.980-0400] {standard_task_runner.py:91} INFO - Job 702: Subtask transform_with_spark
[2024-07-01T19:23:03.056-0400] {task_command.py:426} INFO - Running <TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [running]> on host walter-VirtualBox
[2024-07-01T19:23:03.171-0400] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='api_cuevana3_movie' AIRFLOW_CTX_TASK_ID='transform_with_spark' AIRFLOW_CTX_EXECUTION_DATE='2024-07-01T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-01T04:00:00+00:00'
[2024-07-01T19:23:03.173-0400] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-01T19:23:03.199-0400] {logging_mixin.py:188} INFO - No se pudo obtener el JSON de datos de la pelicula
[2024-07-01T19:23:03.199-0400] {python.py:237} INFO - Done. Returned value was: None
[2024-07-01T19:23:03.200-0400] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-01T19:23:03.216-0400] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=api_cuevana3_movie, task_id=transform_with_spark, run_id=scheduled__2024-07-01T04:00:00+00:00, execution_date=20240701T040000, start_date=20240701T232302, end_date=20240701T232303
[2024-07-01T19:23:03.246-0400] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-01T19:23:03.270-0400] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-01T19:23:03.271-0400] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-01T21:18:01.349-0400] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-01T21:18:01.386-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T21:18:01.398-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T21:18:01.399-0400] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-07-01T21:18:01.443-0400] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_with_spark> on 2024-07-01 04:00:00+00:00
[2024-07-01T21:18:01.450-0400] {standard_task_runner.py:63} INFO - Started process 429218 to run task
[2024-07-01T21:18:01.454-0400] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'api_cuevana3_movie', 'transform_with_spark', 'scheduled__2024-07-01T04:00:00+00:00', '--job-id', '766', '--raw', '--subdir', 'DAGS_FOLDER/movie_recommend.py', '--cfg-path', '/tmp/tmpc6quscut']
[2024-07-01T21:18:01.456-0400] {standard_task_runner.py:91} INFO - Job 766: Subtask transform_with_spark
[2024-07-01T21:18:01.610-0400] {task_command.py:426} INFO - Running <TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [running]> on host walter-VirtualBox
[2024-07-01T21:18:01.814-0400] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='api_cuevana3_movie' AIRFLOW_CTX_TASK_ID='transform_with_spark' AIRFLOW_CTX_EXECUTION_DATE='2024-07-01T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-01T04:00:00+00:00'
[2024-07-01T21:18:01.815-0400] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-01T21:18:01.839-0400] {logging_mixin.py:188} INFO - No se pudo obtener el JSON de datos de la pelicula
[2024-07-01T21:18:01.839-0400] {python.py:237} INFO - Done. Returned value was: None
[2024-07-01T21:18:01.840-0400] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-01T21:18:01.844-0400] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=api_cuevana3_movie, task_id=transform_with_spark, run_id=scheduled__2024-07-01T04:00:00+00:00, execution_date=20240701T040000, start_date=20240702T011801, end_date=20240702T011801
[2024-07-01T21:18:01.924-0400] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-01T21:18:02.001-0400] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-01T21:18:02.011-0400] {local_task_job_runner.py:222} INFO - ::endgroup::
[2024-07-01T23:06:41.004-0400] {local_task_job_runner.py:120} INFO - ::group::Pre task execution logs
[2024-07-01T23:06:41.018-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T23:06:41.023-0400] {taskinstance.py:2076} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [queued]>
[2024-07-01T23:06:41.023-0400] {taskinstance.py:2306} INFO - Starting attempt 1 of 1
[2024-07-01T23:06:41.051-0400] {taskinstance.py:2330} INFO - Executing <Task(PythonOperator): transform_with_spark> on 2024-07-01 04:00:00+00:00
[2024-07-01T23:06:41.058-0400] {standard_task_runner.py:63} INFO - Started process 445803 to run task
[2024-07-01T23:06:41.060-0400] {standard_task_runner.py:90} INFO - Running: ['airflow', 'tasks', 'run', 'api_cuevana3_movie', 'transform_with_spark', 'scheduled__2024-07-01T04:00:00+00:00', '--job-id', '823', '--raw', '--subdir', 'DAGS_FOLDER/movie_recommend.py', '--cfg-path', '/tmp/tmp6073ccd8']
[2024-07-01T23:06:41.062-0400] {standard_task_runner.py:91} INFO - Job 823: Subtask transform_with_spark
[2024-07-01T23:06:41.195-0400] {task_command.py:426} INFO - Running <TaskInstance: api_cuevana3_movie.transform_with_spark scheduled__2024-07-01T04:00:00+00:00 [running]> on host walter-VirtualBox
[2024-07-01T23:06:41.310-0400] {taskinstance.py:2648} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='airflow' AIRFLOW_CTX_DAG_ID='api_cuevana3_movie' AIRFLOW_CTX_TASK_ID='transform_with_spark' AIRFLOW_CTX_EXECUTION_DATE='2024-07-01T04:00:00+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='scheduled__2024-07-01T04:00:00+00:00'
[2024-07-01T23:06:41.311-0400] {taskinstance.py:430} INFO - ::endgroup::
[2024-07-01T23:08:29.553-0400] {python.py:237} INFO - Done. Returned value was: [{'actors': ['Harriet Slater,', 'Adain Bradley,', 'Avantika,', 'Jacob Batalon,', 'Humberly González,', 'Wolfgang Novogratz,', 'Larsen Thompson,', 'Olwen Fouéré,', 'Sunčica Milanović,', 'Alan Wells,', 'Joss Carter,', 'James Swanton,', 'Staša Nikolić,', 'Anna Halberg,', 'Cavin Cornwall,', 'Lucy Ridley,', 'Felix Leech,', 'Vahidin Prelić,', 'Dunja Pavlović,', 'Višnja Obradović,'], 'country': 'United States', 'description': 'Un grupo de amigos de la universidad comienzan a morir de maneras relacionadas con su fortuna después de que les lean los horóscopos.', 'director': 'Spenser Cohen', 'duration': 92, 'genre': ['Terror'], 'image_url': 'https://i0.wp.com/www.themoviedb.org/t/p/w185/Adh7xmtgSIUGZBaMj9VLTmq2G8z.jpg', 'quality': 'HD', 'rating': 6.6, 'title': 'Tarot', 'views': 612, 'year': '2024'}]
[2024-07-01T23:08:29.587-0400] {taskinstance.py:441} INFO - ::group::Post task execution logs
[2024-07-01T23:08:29.784-0400] {taskinstance.py:1206} INFO - Marking task as SUCCESS. dag_id=api_cuevana3_movie, task_id=transform_with_spark, run_id=scheduled__2024-07-01T04:00:00+00:00, execution_date=20240701T040000, start_date=20240702T030641, end_date=20240702T030829
[2024-07-01T23:08:30.074-0400] {local_task_job_runner.py:240} INFO - Task exited with return code 0
[2024-07-01T23:08:30.163-0400] {taskinstance.py:3503} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2024-07-01T23:08:30.164-0400] {local_task_job_runner.py:222} INFO - ::endgroup::
